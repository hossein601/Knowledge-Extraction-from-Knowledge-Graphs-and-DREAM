{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, AdamW\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = load_dataset('cos_e', 'v1.11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$answer$ = It's wrong to make generalizations about people in certain situations.\n",
      "$answer$ = It's good to give someone a ride who needs one.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "\n",
    "# Example to load from the directory named \"formatted_dataset\"\n",
    "loaded_dataset = load_from_disk('./formatted_dataset')\n",
    "\n",
    "# Verify the loaded dataset\n",
    "print(loaded_dataset['train'][1]['generated_output'])\n",
    "print(loaded_dataset['validation'][1]['generated_output'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove \\n$answer$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_answer_prefix(example):\n",
    "    if 'generated_output' in example:\n",
    "        example['generated_output'] = [output.replace(\"$answer$ =\", \"\").strip() for output in example['generated_output']]\n",
    "    return example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0c5cea550e493c810e7d889f2758b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9741 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3e72fd3cab4a42ae8043c4995e290f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1221 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is good to be aware of your surroundings.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "# Apply the function to the dataset\n",
    "transformed_dataset = loaded_dataset.map(remove_answer_prefix, batched=True)\n",
    "\n",
    "# Verify the transformation\n",
    "print(transformed_dataset['train'][0]['generated_output'])\n",
    "print(transformed_dataset['validation'][0]['generated_output'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['']\n"
     ]
    }
   ],
   "source": [
    "print([transformed_dataset['validation'][0]['generated_output']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's wrong to make generalizations about people in certain situations.\n",
      "It's good to give someone a ride who needs one.\n"
     ]
    }
   ],
   "source": [
    "# Verify the transformation\n",
    "print(transformed_dataset['train'][1]['generated_output'])\n",
    "print(transformed_dataset['validation'][1]['generated_output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'question', 'choices', 'answer', 'abstractive_explanation', 'extractive_explanation', 'formatted_question', 'generated_output'],\n",
       "        num_rows: 9741\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'question', 'choices', 'answer', 'abstractive_explanation', 'extractive_explanation', 'formatted_question', 'generated_output'],\n",
       "        num_rows: 1221\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model and tokenizer\n",
    "model_name = \"t5-base\"  # Use \"t5-base\" or \"t5-large\" if resources allow\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "must be change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preprocess the dataset\n",
    "# def preprocess_function(examples):\n",
    "#     inputs = [\"question: \" + q + \" answer: \" + \" \".join(choices) for q, choices in zip(examples['question'], examples['choices'])]\n",
    "#     targets = [\"answer: \" + answer + \" explanation: \" + explanation for answer, explanation in zip(examples['answer'], examples['abstractive_explanation'])]\n",
    "#     model_inputs = tokenizer(inputs, max_length=256, truncation=True, padding='max_length')\n",
    "#     labels = tokenizer(targets, max_length=256, truncation=True, padding='max_length')\n",
    "#     model_inputs['labels'] = labels['input_ids']\n",
    "#     return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dataset\n",
    "def preprocess_function(examples):\n",
    "    # Check if 'generated_output' exists in the examples\n",
    "    if 'generated_output' not in examples:\n",
    "        raise ValueError(\"The 'generated_output' field is missing in the dataset examples.\")\n",
    "\n",
    "    # Concatenate each generated_output to the end of the input\n",
    "    inputs = [\"question: \" + q + \" answer: \" + \" \".join(choices) + \" \" + generated_output\n",
    "              for q, choices, generated_output in zip(examples['question'], examples['choices'], examples['generated_output'])]\n",
    "    \n",
    "    targets = [\"answer: \" + answer + \" explanation: \" + explanation \n",
    "               for answer, explanation in zip(examples['answer'], examples['abstractive_explanation'])]\n",
    "    \n",
    "    model_inputs = tokenizer(inputs, max_length=256, truncation=True, padding='max_length')\n",
    "    labels = tokenizer(targets, max_length=256, truncation=True, padding='max_length')\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    \n",
    "    return model_inputs\n",
    "\n",
    "# Example usage\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac6892b1be44e89b6e32bc0a42e2843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9741 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52993eceeefa44d58955134b4ba5c6df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1221 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_dataset = transformed_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[822, 10, 96, 7238, 33, 335, 16981, 30, 46, 8947, 2195, 5, 5245, 1590, 326, 5, 852, 132, 33, 3, 4, 16981, 535, 363, 19, 48, 46, 677, 13, 58, 1525, 10, 2447, 7089, 484, 2004, 1530, 7270, 682, 18076, 94, 19, 207, 12, 36, 2718, 13, 39, 14338, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1525, 10, 7270, 682, 7295, 10, 765, 3357, 107, 19, 876, 12, 199, 25, 4602, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[822, 10, 71, 36, 9, 624, 19, 214, 21, 740, 813, 1123, 7, 7, 6, 70, 4471, 369, 45, 213, 58, 1525, 10, 3, 2160, 17, 1273, 7632, 5937, 23, 9, 643, 13, 387, 1679, 15, 26, 616, 726, 2814, 7, 3, 172, 32, 32, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1525, 10, 1679, 15, 26, 616, 7295, 10, 2985, 35, 616, 19, 163, 8, 286, 21, 8, 36, 9, 624, 4471, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Print a few examples to verify the preprocessing\n",
    "print(encoded_dataset['train'][0]['input_ids'])\n",
    "print(encoded_dataset['train'][0]['labels'])\n",
    "print(encoded_dataset['validation'][0]['input_ids'])\n",
    "print(encoded_dataset['validation'][0]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1 - Decoded Input: question: \"There are 10 apples on an apple tree. Three fall off. Now there are X apples.\" What is this an example of? answer: park coloring book garden center math problem gravity It is good to be aware of your surroundings.\n",
      "Example 1 - Decoded Label: answer: math problem explanation: webmath is designed to help you solve\n",
      "\n",
      "Example 2 - Decoded Input: question: A John is a bum. Much like the stereotype, he lives near this sort of transportation infrastructure. Where does he live? answer: bus depot beach train station bridge bridge It's wrong to make generalizations about people in certain situations.\n",
      "Example 2 - Decoded Label: answer: bridge explanation: bums are well known to take up residence under bridges.\n",
      "\n",
      "Example 3 - Decoded Input: question: A bad person places little value on being honest, acting without pretense or being what? answer: excellent upright premium competent sincere It's wrong to be a bad person.\n",
      "Example 3 - Decoded Label: answer: sincere explanation: this word is most relavant\n",
      "\n",
      "Example 1 - Decoded Input: question: A beaver is know for building prowess, their supplies come from where? answer: british columbia body of water wooded area pay debts zoo\n",
      "Example 1 - Decoded Label: answer: wooded area explanation: Wooden area is only the place for the beaver supplies.\n",
      "\n",
      "Example 2 - Decoded Input: question: A car was hailed to chauffeur someone to the opera house, where was it heading? answer: go downtown appear suddenly go fast bottom out east It's good to give someone a ride who needs one.\n",
      "Example 2 - Decoded Label: answer: go downtown explanation: Students do everything\n",
      "\n",
      "Example 3 - Decoded Input: question: A child wants to play, what would they likely want? answer: fall down breathe play tag be dismembered by a chainsaw become adult A child's play is likely to be boring.\n",
      "Example 3 - Decoded Label: answer: play tag explanation: tag different ways to play tag\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to decode the encoded inputs and labels for validation\n",
    "def decode_example(example):\n",
    "    input_ids = example['input_ids']\n",
    "    labels = example['labels']\n",
    "    \n",
    "    decoded_input = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "    decoded_label = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    return decoded_input, decoded_label\n",
    "\n",
    "# Decode and print a few examples from the training set\n",
    "for i in range(3):\n",
    "    decoded_input, decoded_label = decode_example(encoded_dataset['train'][i])\n",
    "    print(f\"Example {i + 1} - Decoded Input: {decoded_input}\")\n",
    "    print(f\"Example {i + 1} - Decoded Label: {decoded_label}\\n\")\n",
    "\n",
    "# Decode and print a few examples from the validation set\n",
    "for i in range(3):\n",
    "    decoded_input, decoded_label = decode_example(encoded_dataset['validation'][i])\n",
    "    print(f\"Example {i + 1} - Decoded Input: {decoded_input}\")\n",
    "    print(f\"Example {i + 1} - Decoded Label: {decoded_label}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'question', 'choices', 'answer', 'abstractive_explanation', 'extractive_explanation', 'formatted_question', 'generated_output', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 1221\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Convert dataset to PyTorch tensors\n",
    "encoded_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(encoded_dataset['train'], batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(encoded_dataset['validation'], batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manavi/myenv/lib/python3.9/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_loop(model, loader, optimizer, accumulation_steps=2):\n",
    "    model.train()\n",
    "    batch_losses = []\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for i, batch in enumerate(tqdm(loader, desc='Training:')):\n",
    "        inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'], labels=labels)\n",
    "        loss = outputs.loss / accumulation_steps  # normalize loss\n",
    "\n",
    "        batch_loss_value = loss.item() * accumulation_steps  # convert to original loss value for logging\n",
    "        loss.backward()\n",
    "\n",
    "        if (i + 1) % accumulation_steps == 0:  # update weights every accumulation_steps mini-batches\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()  # reset gradients\n",
    "\n",
    "        batch_losses.append(batch_loss_value)\n",
    "\n",
    "    # Update remaining gradients if the number of batches is not a multiple of accumulation_steps\n",
    "    if len(loader) % accumulation_steps != 0:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    loss_value = sum(batch_losses) / len(batch_losses)\n",
    "    return {'train_loss': loss_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_sentences(list_of_lists):\n",
    "    sentences = [' '.join(inner_list) for inner_list in list_of_lists]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:: 100%|██████████| 609/609 [06:22<00:00,  1.59it/s]\n",
      "Validation:: 100%|██████████| 77/77 [01:15<00:00,  1.03it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Train Loss: 0.1387\n",
      "Validation Loss: 0.1272\n",
      "Validation Accuracy: 0.3104\n",
      "Validation BERTScore (Explanations): 0.0741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:: 100%|██████████| 609/609 [06:23<00:00,  1.59it/s]\n",
      "Validation:: 100%|██████████| 77/77 [01:16<00:00,  1.01it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3\n",
      "Train Loss: 0.1257\n",
      "Validation Loss: 0.1228\n",
      "Validation Accuracy: 0.3636\n",
      "Validation BERTScore (Explanations): 0.0827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:: 100%|██████████| 609/609 [06:24<00:00,  1.59it/s]\n",
      "Validation:: 100%|██████████| 77/77 [01:16<00:00,  1.01it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3\n",
      "Train Loss: 0.1197\n",
      "Validation Loss: 0.1205\n",
      "Validation Accuracy: 0.4046\n",
      "Validation BERTScore (Explanations): 0.0300\n"
     ]
    }
   ],
   "source": [
    "import bert_score\n",
    "from datasets import load_metric\n",
    "def validate_loop(model, loader):\n",
    "    model.eval()\n",
    "    batch_losses = []\n",
    "    accuracy_preds = []\n",
    "    accuracy_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc='Validation:'):\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'], labels=labels)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            # Generate predictions\n",
    "            predictions = model.generate(inputs['input_ids'], attention_mask=inputs['attention_mask'], max_length=512)\n",
    "\n",
    "            # Decode predictions and labels\n",
    "            decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "            # Print decoded predictions and labels for debugging\n",
    "            # print(\"Decoded predictions:\")\n",
    "            # for pred in decoded_preds:\n",
    "            #     print(f\"'{pred}'\")\n",
    "            # print(\"Decoded labels:\")\n",
    "            # for label in decoded_labels:\n",
    "            #     print(f\"'{label}'\")\n",
    "\n",
    "            # # Extract the answers from decoded predictions and labels\n",
    "            # extracted_preds = [pred.strip().split('.')[0] for pred in decoded_preds if pred.strip()]\n",
    "            # extracted_labels = [label.strip().split('.')[0] for label in decoded_labels if label.strip()]\n",
    "            # Extract the answers from decoded predictions and labels\n",
    "            extracted_preds = [pred.split('answer: ')[1].split(' ')[0] for pred in decoded_preds if 'answer: ' in pred]\n",
    "            extracted_labels = [label.split('answer: ')[1].split(' ')[0] for label in decoded_labels if 'answer: ' in label]\n",
    "            \n",
    "            explanations_preds = [pred.split('explanation: ')[1].split(' ') for pred in decoded_preds if 'explanation: ' in pred]\n",
    "            explanations_labels = [label.split('explanation: ')[1].split(' ') for label in decoded_labels if 'explanation: ' in label]\n",
    "            # print(convert_to_sentences(explanations_preds))\n",
    "            # print(convert_to_sentences(explanations_labels))\n",
    "            \n",
    "            # Ensure lengths match for accuracy calculation\n",
    "            if len(extracted_preds) == len(extracted_labels):\n",
    "                accuracy_preds.extend(extracted_preds)\n",
    "                accuracy_labels.extend(extracted_labels)\n",
    "\n",
    "            batch_losses.append(loss.item())\n",
    "\n",
    "    # Calculate accuracy\n",
    "    correct = sum(p == l for p, l in zip(accuracy_preds, accuracy_labels))\n",
    "    accuracy = correct / len(accuracy_preds) if accuracy_preds else 0.0\n",
    "    \n",
    "    \n",
    "    # Calculate BERTScore for explanations (explanations_preds and explanations_labels)\n",
    "    P_exp, R_exp, F1_exp = bert_score.score(convert_to_sentences(explanations_preds), convert_to_sentences(explanations_labels), lang=\"en\", rescale_with_baseline=True)\n",
    "    bertscore_exp_avg = F1_exp.mean().item()\n",
    "\n",
    "    loss_value = sum(batch_losses) / len(batch_losses)\n",
    "    # return {'val_loss': loss_value, 'accuracy': accuracy}\n",
    "    # return {'val_loss': loss_value, 'bertscore_exp': bertscore_exp_avg}\n",
    "    return {'val_loss': loss_value, 'accuracy': accuracy, 'bertscore_exp': bertscore_exp_avg}\n",
    "\n",
    "\n",
    "# # Training and validation\n",
    "# num_epochs = 1\n",
    "# for epoch in range(num_epochs):\n",
    "#     train_metrics = train_loop(model, train_loader, optimizer)\n",
    "#     val_metrics = validate_loop(model, val_loader)\n",
    "\n",
    "#     print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "#     print(f\"Train Loss: {train_metrics['train_loss']:.4f}\")\n",
    "#     print(f\"Validation Loss: {val_metrics['val_loss']:.4f}\")\n",
    "#     print(f\"Validation Accuracy: {val_metrics['accuracy']:.4f}\")\n",
    "    \n",
    "# Training and validation\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    train_metrics = train_loop(model, train_loader, optimizer)\n",
    "    val_metrics = validate_loop(model, val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_metrics['train_loss']:.4f}\")\n",
    "    print(f\"Validation Loss: {val_metrics['val_loss']:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_metrics['accuracy']:.4f}\")\n",
    "    print(f\"Validation BERTScore (Explanations): {val_metrics['bertscore_exp']:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
